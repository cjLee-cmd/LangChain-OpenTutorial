{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7562937",
   "metadata": {},
   "source": [
    "# HTMLHeaderTextSplitter  \n",
    "\n",
    "- Author: [ChangJun Lee](https://www.linkedin.com/in/cjleeno1/)\n",
    "- Design: []() \n",
    "- Peer Review: [YooKyung Jeon](https://github.com/sirena1), [Wooseok Jeong](https://github.com/jeong-wooseok)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab] [![Open in GitHub]\n",
    "\n",
    "## Overview\n",
    "\n",
    "This is a \"structure-aware\" chunk generator that splits text at the element level and adds metadata for each header, conceptually similar to the <a href=\"https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/markdown_header_metadata\">`MarkdownHeaderTextSplitter`</a>.\n",
    "\n",
    "It adds metadata \"related\" to each chunk.\n",
    "\n",
    "`HTMLHeaderTextSplitter` can return chunks by element or combine elements with the same metadata,\n",
    "\n",
    "- (a) semantically (approximately) group related text and\n",
    "- (b) preserve context-rich information encoded in the document structure.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Using HTML Strings](#using-html-strings)\n",
    "- [Connecting with Other Splitters and Loading HTML from a Web URL](#connecting-with-other-splitters-and-loading-html-from-a-web-url)\n",
    "- [Limitations](#limitations)\n",
    "\n",
    "### References \n",
    "\n",
    "- [HTML Header Text Splitter](https://python.langchain.com/api_reference/text_splitters/html/langchain_text_splitters.html.HTMLHeaderTextSplitter.html#)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029d53c",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Setting up your environment is the first step. See the [Environment Setup](https://wikidocs.net/257836) guide for more details.\n",
    "\n",
    "**[Note]**\n",
    "- The `langchain-opentutorial` is a package of easy-to-use environment setup guidance, useful functions and utilities for tutorials.\n",
    "- Check out the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cc73e",
   "metadata": {},
   "source": [
    "## Using HTML Strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6331f3",
   "metadata": {},
   "source": [
    "- Specify the header tags and their names to split on in the `headers_to_split_on` list as tuples.\n",
    "- Create an `HTMLHeaderTextSplitter` object and pass the list of headers to split on to the `headers_to_split_on` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b4943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb85c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current environment: mac-py3.11\n",
      "Release type or date: stable\n",
      "Installing packages: langsmith, langchain, langchain_core, langchain_community, langchain_text_splitters, langchain_openai...\n",
      "Warning: No specific version found for langsmith, using latest\n",
      "Warning: No specific version found for langchain_core, using latest\n",
      "Warning: No specific version found for langchain_community, using latest\n",
      "Warning: No specific version found for langchain_text_splitters, using latest\n",
      "Warning: No specific version found for langchain_openai, using latest\n",
      "Requirement already satisfied: langsmith in /opt/homebrew/lib/python3.11/site-packages (0.2.11)\n",
      "Requirement already satisfied: langchain==0.3.13 in /opt/homebrew/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: langchain_core in /opt/homebrew/lib/python3.11/site-packages (0.3.30)\n",
      "Requirement already satisfied: langchain_community in /opt/homebrew/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: langchain_text_splitters in /opt/homebrew/lib/python3.11/site-packages (0.3.5)\n",
      "Requirement already satisfied: langchain_openai in /opt/homebrew/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (3.11.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain==0.3.13) (9.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/lib/python3.11/site-packages (from langsmith) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.11/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/cjlee/Library/Python/3.11/lib/python/site-packages (from langchain_core) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/cjlee/Library/Python/3.11/lib/python/site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain_community) (2.7.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /opt/homebrew/lib/python3.11/site-packages (from langchain_openai) (1.59.8)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.13) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.13) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.13) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.13) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3.13) (2.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Successfully installed: langsmith, langchain==0.3.13, langchain_core, langchain_community, langchain_text_splitters, langchain_openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_openai\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0831a0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"RecursiveJsonSplitter\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d71c85ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header 1\n",
      "{}\n",
      "=====================\n",
      "Text included in Header 1  \n",
      "Header 2-1 Title Header 3-1 Title Header 3-2 Title\n",
      "{'Header 1': 'Header 1'}\n",
      "=====================\n",
      "Text included in Header 2-1\n",
      "{'Header 1': 'Header 1', 'Header 2': 'Header 2-1 Title'}\n",
      "=====================\n",
      "Text included in Header 3-1\n",
      "{'Header 1': 'Header 1', 'Header 2': 'Header 2-1 Title', 'Header 3': 'Header 3-1 Title'}\n",
      "=====================\n",
      "Text included in Header 3-2\n",
      "{'Header 1': 'Header 1', 'Header 2': 'Header 2-1 Title', 'Header 3': 'Header 3-2 Title'}\n",
      "=====================\n",
      "Header 2-2 Title\n",
      "{'Header 1': 'Header 1'}\n",
      "=====================\n",
      "Text included in Header 2-2\n",
      "{'Header 1': 'Header 1', 'Header 2': 'Header 2-2 Title'}\n",
      "=====================\n",
      "Last content\n",
      "{'Header 1': 'Header 1'}\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Header 1</h1>\n",
    "        <p>Text included in Header 1</p>\n",
    "        <div>\n",
    "            <h2>Header 2-1 Title</h2>\n",
    "            <p>Text included in Header 2-1</p>\n",
    "            <h3>Header 3-1 Title</h3>\n",
    "            <p>Text included in Header 3-1</p>\n",
    "            <h3>Header 3-2 Title</h3>\n",
    "            <p>Text included in Header 3-2</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Header 2-2 Title</h2>\n",
    "            <p>Text included in Header 2-2</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Last content</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),  # Specify the header tags and their names to split on.\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "# Create an HTMLHeaderTextSplitter object to split the HTML text based on the specified headers.\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "# Split the HTML string and store the result in the html_header_splits variable.\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "# Print the split results.\n",
    "for header in html_header_splits:\n",
    "    print(f\"{header.page_content}\")\n",
    "    print(f\"{header.metadata}\", end=\"\\n=====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d970ec",
   "metadata": {},
   "source": [
    "## Connecting with Other Splitters and Loading HTML from a Web URL\n",
    "\n",
    "In this example, we load HTML content from a web URL and then process it by connecting it with other splitters in a pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c51d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We see that Gödel first tried to reduce the consistency problem for analysis to that of arithmetic. This seemed to require a truth definition for arithmetic, which in turn led to paradoxes, such as the Liar paradox (“This sentence is false”) and Berry’s paradox (“The least number not defined by an expression consisting of just fourteen English words”). Gödel then noticed that such paradoxes would not necessarily arise if truth were replaced by provability. But this means that arithmetic truth\n",
      "{'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.1 The First Incompleteness Theorem'}\n",
      "=====================\n",
      "means that arithmetic truth and arithmetic provability are not co-extensive — whence the First Incompleteness Theorem.\n",
      "{'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.1 The First Incompleteness Theorem'}\n",
      "=====================\n",
      "This account of Gödel’s discovery was told to Hao Wang very much after the fact; but in Gödel’s contemporary correspondence with Bernays and Zermelo, essentially the same description of his path to the theorems is given. (See Gödel 2003a and Gödel 2003b respectively.) From those accounts we see that the undefinability of truth in arithmetic, a result credited to Tarski, was likely obtained in some form by Gödel by 1931. But he neither publicized nor published the result; the biases logicians\n",
      "{'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.1 The First Incompleteness Theorem'}\n",
      "=====================\n",
      "result; the biases logicians had expressed at the time concerning the notion of truth, biases which came vehemently to the fore when Tarski announced his results on the undefinability of truth in formal systems 1935, may have served as a deterrent to Gödel’s publication of that theorem.\n",
      "{'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.1 The First Incompleteness Theorem'}\n",
      "=====================\n",
      "We now describe the proof of the two theorems, formulating Gödel’s results in Peano arithmetic. Gödel himself used a system related to that defined in Principia Mathematica, but containing Peano arithmetic. In our presentation of the First and Second Incompleteness Theorems we refer to Peano arithmetic as P, following Gödel’s notation.\n",
      "{'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.2 The proof of the First Incompleteness Theorem'}\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "url = \"https://plato.stanford.edu/entries/goedel/\"  # Specify the URL of the text to split.\n",
    "\n",
    "headers_to_split_on = [  # Specify the HTML header tags and their names to split on.\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "]\n",
    "\n",
    "# Create an HTMLHeaderTextSplitter object to split the text based on the specified HTML headers.\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Fetch the text from the URL and split it based on the HTML headers.\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "\n",
    "chunk_size = 500  # Specify the size of the chunks to split the text into.\n",
    "chunk_overlap = 30  # Specify the number of overlapping characters between chunks.\n",
    "text_splitter = RecursiveCharacterTextSplitter(  # Create a RecursiveCharacterTextSplitter object to recursively split the text.\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "# Split the text that was split by HTML headers into chunks of the specified size.\n",
    "splits = text_splitter.split_documents(html_header_splits)\n",
    "\n",
    "# Print chunks 80 to 85 of the split text.\n",
    "for header in splits[80:85]:\n",
    "    print(f\"{header.page_content}\")\n",
    "    print(f\"{header.metadata}\", end=\"\\n=====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362cc91",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "HTMLHeaderTextSplitter attempts to handle structural differences between HTML documents, but it may sometimes miss specific headers.\n",
    "\n",
    "For example, this algorithm assumes that headers are always nodes \"above\" the related text, i.e., in previous sibling nodes, ancestor nodes, and combinations thereof.\n",
    "\n",
    "In the following news article (as of the time of writing), the text of the top headline is tagged as \"h1\", but it is in a **separate subtree** from the text element we expect.\n",
    "\n",
    "Therefore, the text related to the \"h1\" element does not appear in the chunk metadata, but the text related to \"h2\" does, if applicable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147313da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN values your feedback  \n",
      "1. How relevant is this ad to you?  \n",
      "2. Did you encounter any technical i\n",
      "{}\n",
      "=====================\n",
      "No two El Niño winters are the same, but many have temperature and precipitation trends in common.  \n",
      "{'Header 2': 'What could this winter look like?'}\n",
      "=====================\n",
      "Ad Feedback  \n",
      "Ad Feedback  \n",
      "Ad Feedback  \n",
      "Ad Feedback  \n",
      "Ad Feedback  \n",
      "Ad Feedback  \n",
      "Ad Feedback  \n",
      "Ad\n",
      "{}\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "# Specify the URL of the HTML page to split.\n",
    "url = \"https://www.cnn.com/2023/09/25/weather/el-nino-winter-us-climate/index.html\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),  # Specify the header tags and their names to split on.\n",
    "    (\"h2\", \"Header 2\"),  # Specify the header tags and their names to split on.\n",
    "]\n",
    "\n",
    "# Create an HTMLHeaderTextSplitter object to split the HTML text based on the specified headers.\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Split the HTML page from the specified URL and store the result in the html_header_splits variable.\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "\n",
    "# Print the split results.\n",
    "for header in html_header_splits:\n",
    "    print(f\"{header.page_content[:100]}\")\n",
    "    print(f\"{header.metadata}\", end=\"\\n=====================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
